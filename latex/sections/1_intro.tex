\chapter{Introduction}\label{ch:Intro}

Robotic hands are becoming increasingly common in research and industry. Modern robotic hands often have many degrees of freedom (DoF) to imitate the dexterity of the human hand, which has over 20 DoF. However, controlling these high-DoF robotic hands is a complex task: while the human brain controls the hand easily using coordinated patterns called \textit{synergies} \cite{santello1998postural}, explicitly controlling 15 or more motors of a robotic hand would be impractical.

This project addresses the problem of \textit{motion retargeting} from a human hand to a non-anthropomorphic robotic hand. The goal is to leverage human hand synergies to control a robotic hand with a different kinematic structure to that of the human hand. To do this, we use an object-based mapping approach called the \textit{virtual sphere} method \cite{gioioso2013mapping}, which focuses on the interaction between the hand and the object being manipulated.

\section{The correspondence problem}
A major challenge in teleoperation is the \textit{correspondence problem}. Human hands and robotic hands are rarely identical: they usually have different bone lengths, different types of joints, and a different number of fingers. Because of these differences, standard mapping techniques fail to accurately translate human motion.
\begin{itemize}
    \item \textit{Joint-to-joint mapping}: this method copies the angles of the human joints directly to the robot. This is often impossible because the robot might have fewer joints than the human, or the joints might rotate around different axes, leading to unnatural poses.
    \item \textit{Fingertip mapping}: this method forces the robot's fingertips to follow the position of the human fingertips. Although this ensures contact points are reached, it ignores the position of the palm and the rest of the fingers, causing the robot hand to collide with itself or reach impossible configurations.
\end{itemize}

To solve this, we adopt an approach proposed by Gioioso et al. \cite{gioioso2013mapping} that works in the \textit{object domain}. Instead of mapping the anatomy of the hand directly, we map the effect that the hand has on a virtual object (a sphere) held in the hand.

\section{Synergy-driven input}
To control the robotic hand, we first need a reliable reconstruction of the human hand pose. In this project, we use the Weart TouchDIVER G1 haptic glove in Figure \ref{fig:weart_glove}, which provides the closure of three fingers (thumb, index, middle) and the abduction of the thumb, plus other measurements that are not of interest for this work.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.25\textwidth]{images/weart_glove} 
    \caption{The Weart TouchDIVER G1 haptic glove. Image source: \cite{weart_website}.}
    \label{fig:weart_glove}
\end{figure}

To reconstruct the full hand pose from this limited input, we rely on a reconstruction system developed in a previous work by Primiceri et al. \cite{primiceri2025motion}. Their system uses neural networks to estimate the full human hand pose from the sparse glove data, based on the theory of \textit{postural synergies} \cite{santello1998postural}. We take this reconstructed hand pose as the input for our motion retargeting system, focusing on the mathematical translation of this motion to the robotic hand.

\section{Objective}
Our main goal is to implement and validate a robust pipeline that allows a human operator to control robotic hands with different kinematics in real-time. Specifically, we present an algorithm that creates a virtual sphere inside the human hand and maps its deformation and movement to the robotic hand. Thanks to the mapping in the domain of the manipulated object, we create a generalized kinematic solver that can handle different robotic structures (e.g., from a 5-fingered hand to a 3-fingered one, or a 2-fingered gripper) without needing to redesign the mapping for each case. Finally, we evaluate the performance of our system by *TODO: add evaluation details*.

\section{Structure}
The rest of this report is structured as follows. In Chapter \ref{Ch:background} we review the relevant literature on hand synergies and motion retargeting techniques. In Chapter \ref{Ch:framework} we provide a mathematical formulation of the virtual sphere method and our implementation details. In Chapter \ref{Ch:setup} we describe the system architecture, including the hardware and software components used. In Chapter \ref{Ch:results} we present the results of our experiments and evaluate the performance of the retargeting system. Finally, in Chapter \ref{Ch:conclusion} we summarize our findings and discuss potential future work.